{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team K** - <span style=\"color:green; font-weight:bold\">Kathirvel G</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Case Study 11 : Production Orders and Lead Times*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*First server connection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected Successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_22088\\3309132947.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df=pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd \n",
    "\n",
    "server = 'LAPTOP-01FKSP77'\n",
    "database = 'AdventureWorks2022'\n",
    "username = 'sa'\n",
    "password = '1234'\n",
    " \n",
    "\n",
    "connection_string = f'DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "\n",
    "try:\n",
    "    conn = pyodbc.connect(connection_string)\n",
    "    print(\"Connected Successfully\")\n",
    "    query = \"Select Top 10 * from [AdventureWorks2022].[HumanResources].[Department]\"\n",
    "    df=pd.read_sql(query, conn)\n",
    "    df\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_22088\\2079243987.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  sales_data=pd.read_sql(query,conn)\n"
     ]
    }
   ],
   "source": [
    "query=\"select * from [Sales].[SalesPerson]\"\n",
    "sales_data=pd.read_sql(query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.to_csv(\"sales_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kathir'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n",
    "\n",
    "##\n",
    "##SELECT HOST_NAME() AS HostName;\n",
    "\n",
    "SELECT @@SERVERNAME AS ServerName;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_35380\\2629750605.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  tables_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 TABLE_NAME\n",
      "0              SalesTaxRate\n",
      "1          PersonCreditCard\n",
      "2               PersonPhone\n",
      "3            SalesTerritory\n",
      "4           PhoneNumberType\n",
      "..                      ...\n",
      "67                 Location\n",
      "68                 Password\n",
      "69  SalesPersonQuotaHistory\n",
      "70                   Person\n",
      "71              SalesReason\n",
      "\n",
      "[72 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE'\"\n",
    "tables_df = pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "print(tables_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green; font-weight:bold\">detailed info about columns in all tables</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_4028\\3969874226.py:13: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  columns_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TABLE_NAME        COLUMN_NAME DATA_TYPE  CHARACTER_MAXIMUM_LENGTH  \\\n",
      "0             Address          AddressID       int                       NaN   \n",
      "1             Address       AddressLine1  nvarchar                      60.0   \n",
      "2             Address       AddressLine2  nvarchar                      60.0   \n",
      "3             Address               City  nvarchar                      30.0   \n",
      "4             Address    StateProvinceID       int                       NaN   \n",
      "..                ...                ...       ...                       ...   \n",
      "744  WorkOrderRouting      ActualEndDate  datetime                       NaN   \n",
      "745  WorkOrderRouting  ActualResourceHrs   decimal                       NaN   \n",
      "746  WorkOrderRouting        PlannedCost     money                       NaN   \n",
      "747  WorkOrderRouting         ActualCost     money                       NaN   \n",
      "748  WorkOrderRouting       ModifiedDate  datetime                       NaN   \n",
      "\n",
      "    IS_NULLABLE  \n",
      "0            NO  \n",
      "1            NO  \n",
      "2           YES  \n",
      "3            NO  \n",
      "4            NO  \n",
      "..          ...  \n",
      "744         YES  \n",
      "745         YES  \n",
      "746          NO  \n",
      "747         YES  \n",
      "748          NO  \n",
      "\n",
      "[749 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    TABLE_NAME, \n",
    "    COLUMN_NAME, \n",
    "    DATA_TYPE, \n",
    "    CHARACTER_MAXIMUM_LENGTH, \n",
    "    IS_NULLABLE \n",
    "FROM \n",
    "    INFORMATION_SCHEMA.COLUMNS\n",
    "ORDER BY TABLE_NAME\n",
    "\"\"\"\n",
    "columns_df = pd.read_sql(query, conn)\n",
    "print(columns_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green; font-weight:bold\">to check if the WorkOrder table exists in the database </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_4028\\3947587245.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  workorder_exists = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkOrder table exists in the database.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT TABLE_NAME \n",
    "FROM INFORMATION_SCHEMA.TABLES \n",
    "WHERE TABLE_NAME = 'WorkOrder'\n",
    "\"\"\"\n",
    "workorder_exists = pd.read_sql(query, conn)\n",
    "\n",
    "if not workorder_exists.empty:\n",
    "    print(\"WorkOrder table exists in the database.\")\n",
    "else:\n",
    "    print(\"WorkOrder table does not exist in the database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkOrder is not a DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# if 'WorkOrder' in globals() and isinstance(WorkOrder, pd.DataFrame):\n",
    "#     print(\"WorkOrder is a Pandas DataFrame.\")\n",
    "# else:\n",
    "#     print(\"WorkOrder is not a DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Select WorkOrderID, OrderQty, and ProductID columns from the WorkOrder DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_35380\\3597360701.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  workorder_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   WorkOrderID  OrderQty  ProductID\n",
      "0            1         8        722\n",
      "1            2        15        725\n",
      "2            3         9        726\n",
      "3            4        16        729\n",
      "4            5        14        730\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT WorkOrderID, OrderQty, ProductID \n",
    "FROM Production.WorkOrder\n",
    "\"\"\"\n",
    "workorder_df = pd.read_sql(query, conn)\n",
    "print(workorder_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green; font-weight:bold\">to find the schema </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_35380\\508003651.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_info = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TABLE_SCHEMA TABLE_NAME\n",
      "0   Production  WorkOrder\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT TABLE_SCHEMA, TABLE_NAME \n",
    "FROM INFORMATION_SCHEMA.TABLES \n",
    "WHERE TABLE_NAME = 'WorkOrder'\n",
    "\"\"\"\n",
    "schema_info = pd.read_sql(query, conn)\n",
    "print(schema_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2) Sort the WorkOrder DataFrame by OrderQty in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WorkOrderID  OrderQty  ProductID\n",
      "39423        39424     39570          3\n",
      "42064        42065     39270          3\n",
      "50529        50530     34620          3\n",
      "17733        17734     33420          3\n",
      "47659        47660     33040          3\n",
      "...            ...       ...        ...\n",
      "46074        46075         1        977\n",
      "46073        46074         1        967\n",
      "46072        46073         1        959\n",
      "46071        46072         1        956\n",
      "36295        36296         1        996\n",
      "\n",
      "[72591 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "sorted_workorder_df = workorder_df.sort_values(by='OrderQty', ascending=False)\n",
    "print(sorted_workorder_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "work order df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_35380\\1562150801.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  workorder_df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WorkOrderID  ProductID  OrderQty  StockedQty  ScrappedQty  StartDate  \\\n",
      "0                1        722         8           8            0 2011-06-03   \n",
      "1                2        725        15          15            0 2011-06-03   \n",
      "2                3        726         9           9            0 2011-06-03   \n",
      "3                4        729        16          16            0 2011-06-03   \n",
      "4                5        730        14          14            0 2011-06-03   \n",
      "...            ...        ...       ...         ...          ...        ...   \n",
      "72586        72587        804        19          19            0 2014-06-02   \n",
      "72587        72588        316        52          52            0 2014-06-02   \n",
      "72588        72589        331        52          52            0 2014-06-02   \n",
      "72589        72590        350        26          26            0 2014-06-02   \n",
      "72590        72591        531        26          26            0 2014-06-02   \n",
      "\n",
      "         EndDate    DueDate  ScrapReasonID ModifiedDate  \n",
      "0     2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "1     2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "2     2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "3     2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "4     2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "...          ...        ...            ...          ...  \n",
      "72586 2014-06-13 2014-06-13            NaN   2014-06-13  \n",
      "72587 2014-06-12 2014-06-13            NaN   2014-06-12  \n",
      "72588 2014-06-12 2014-06-13            NaN   2014-06-12  \n",
      "72589 2014-06-12 2014-06-13            NaN   2014-06-12  \n",
      "72590 2014-06-12 2014-06-13            NaN   2014-06-12  \n",
      "\n",
      "[72591 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM Production.WorkOrder\"\n",
    "workorder_df = pd.read_sql(query, conn)\n",
    "print(workorder_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Retrieve distinct ProductID values from the WorkOrder DataFrame.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[722 725 726 729 730 732 733 738 741 742 743 745 747 748 749 753 754 755\n",
      " 756 758 760 761 762 763 764 765 766 767 768 770 771 772 773 774 775 776\n",
      " 777 778 516 517 518 519 717 721 723 724 727 731 734 735 736 739 740 744\n",
      " 806 807 810 811 812 813 817 818 819 820 825 826 827 828 894 945 950 951\n",
      " 994 995 996   3 324 327 328 329 398 399 400 401 529 532 533 534 802 803\n",
      " 804 316 331 350 531 750 718 751 752 719 720 759 728 769 737 757 779 780\n",
      " 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798\n",
      " 799 800 801 805 808 809 814 815 816 822 823 824 830 831 832 833 835 836\n",
      " 838 839 515 680 706 746 834 840 885 886 887 888 889 890 891 892 893 895\n",
      " 896 898 899 900 902 903 904 905 906 917 918 919 920 924 925 926 927 942\n",
      " 943 944 946 947 949 953 954 955 956 957 958 959 960 961 962 963 964 965\n",
      " 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983\n",
      " 984 985 986 987 988 989 990 991 992 993 997 998 999 514 520 521 522 821\n",
      " 829 897 901 330]\n"
     ]
    }
   ],
   "source": [
    "distinct_product_ids = workorder_df['ProductID'].unique()\n",
    "print(distinct_product_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Filter work orders with OrderQty greater than 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WorkOrderID  ProductID  OrderQty  StockedQty  ScrappedQty  StartDate  \\\n",
      "87              88          3      4600        4600            0 2011-06-03   \n",
      "88              89        324      1148        1148            0 2011-06-03   \n",
      "89              90        327       574         574            0 2011-06-03   \n",
      "91              92        329       680         680            0 2011-06-03   \n",
      "93              94        399       574         574            0 2011-06-03   \n",
      "...            ...        ...       ...         ...          ...        ...   \n",
      "69501        69502        350      4387        4387            0 2014-05-04   \n",
      "69502        69503        531      4387        4387            0 2014-05-04   \n",
      "70014        70015          3       510         510            0 2014-05-09   \n",
      "70560        70561          3       510         510            0 2014-05-14   \n",
      "70873        70874          3       590         590            0 2014-05-17   \n",
      "\n",
      "         EndDate    DueDate  ScrapReasonID ModifiedDate  \n",
      "87    2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "88    2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "89    2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "91    2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "93    2011-06-13 2011-06-14            NaN   2011-06-13  \n",
      "...          ...        ...            ...          ...  \n",
      "69501 2014-05-14 2014-05-15            NaN   2014-05-14  \n",
      "69502 2014-05-14 2014-05-15            NaN   2014-05-14  \n",
      "70014 2014-05-19 2014-05-20            NaN   2014-05-19  \n",
      "70560 2014-05-24 2014-05-25            NaN   2014-05-24  \n",
      "70873 2014-05-27 2014-05-28            NaN   2014-05-27  \n",
      "\n",
      "[1157 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered_workorder_df = workorder_df[workorder_df['OrderQty'] > 500]\n",
    "print(filtered_workorder_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Count the total number of work orders in the WorkOrder DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72591\n"
     ]
    }
   ],
   "source": [
    "total_work_orders = workorder_df.shape[0]\n",
    "print(total_work_orders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Find work orders that are still in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WorkOrderID', 'ProductID', 'OrderQty', 'StockedQty', 'ScrappedQty',\n",
      "       'StartDate', 'EndDate', 'DueDate', 'ScrapReasonID', 'ModifiedDate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(workorder_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [WorkOrderID, ProductID, OrderQty, StockedQty, ScrappedQty, StartDate, EndDate, DueDate, ScrapReasonID, ModifiedDate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "workorder_df['StartDate'] = pd.to_datetime(workorder_df['StartDate'])\n",
    "workorder_df['EndDate'] = pd.to_datetime(workorder_df['EndDate'])\n",
    "current_date = datetime.now()\n",
    "in_progress_workorders_df = workorder_df[(workorder_df['StartDate'] <= current_date) & (workorder_df['EndDate'].isna() | (workorder_df['EndDate'] >= current_date))]\n",
    "print(in_progress_workorders_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Check for any work orders without start dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [WorkOrderID, ProductID, OrderQty, StockedQty, ScrappedQty, StartDate, EndDate, DueDate, ScrapReasonID, ModifiedDate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "orders_without_start_date_df = workorder_df[workorder_df['StartDate'].isna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Select work orders scheduled to start in the next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [WorkOrderID, ProductID, OrderQty, StockedQty, ScrappedQty, StartDate, EndDate, DueDate, ScrapReasonID, ModifiedDate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "workorder_df['StartDate'] = pd.to_datetime(workorder_df['StartDate'])\n",
    "current_date = datetime.now()\n",
    "one_week_from_now = current_date + timedelta(weeks=1)\n",
    "next_week_start_workorders_df = workorder_df[\n",
    "    (workorder_df['StartDate'] > current_date) & \n",
    "    (workorder_df['StartDate'] <= one_week_from_now)\n",
    "]\n",
    "print(next_week_start_workorders_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Calculate the total production quantity by product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ProductID  TotalProductionQuantity\n",
      "0            3                   911890\n",
      "1          316                   236002\n",
      "2          324                   234734\n",
      "3          327                   117367\n",
      "4          328                    62302\n",
      "..         ...                      ...\n",
      "233        995                    26956\n",
      "234        996                    23085\n",
      "235        997                      656\n",
      "236        998                     1556\n",
      "237        999                     1338\n",
      "\n",
      "[238 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "total_production_quantity_by_product = workorder_df.groupby('ProductID')['OrderQty'].sum().reset_index()\n",
    "total_production_quantity_by_product.columns = ['ProductID', 'TotalProductionQuantity']\n",
    "print(total_production_quantity_by_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Merge the WorkOrder and Product DataFrames on ProductID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_4028\\3610438710.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  product_df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM Production.Product\"\n",
    "product_df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WorkOrderID  ProductID  OrderQty  StockedQty  ScrappedQty  StartDate  \\\n",
      "0                1        722         8           8            0 2011-06-03   \n",
      "1                2        725        15          15            0 2011-06-03   \n",
      "2                3        726         9           9            0 2011-06-03   \n",
      "3                4        729        16          16            0 2011-06-03   \n",
      "4                5        730        14          14            0 2011-06-03   \n",
      "...            ...        ...       ...         ...          ...        ...   \n",
      "72586        72587        804        19          19            0 2014-06-02   \n",
      "72587        72588        316        52          52            0 2014-06-02   \n",
      "72588        72589        331        52          52            0 2014-06-02   \n",
      "72589        72590        350        26          26            0 2014-06-02   \n",
      "72590        72591        531        26          26            0 2014-06-02   \n",
      "\n",
      "         EndDate    DueDate  ScrapReasonID ModifiedDate_x  ... ProductLine  \\\n",
      "0     2011-06-13 2011-06-14            NaN     2011-06-13  ...          R    \n",
      "1     2011-06-13 2011-06-14            NaN     2011-06-13  ...          R    \n",
      "2     2011-06-13 2011-06-14            NaN     2011-06-13  ...          R    \n",
      "3     2011-06-13 2011-06-14            NaN     2011-06-13  ...          R    \n",
      "4     2011-06-13 2011-06-14            NaN     2011-06-13  ...          R    \n",
      "...          ...        ...            ...            ...  ...         ...   \n",
      "72586 2014-06-13 2014-06-13            NaN     2014-06-13  ...        None   \n",
      "72587 2014-06-12 2014-06-13            NaN     2014-06-12  ...        None   \n",
      "72588 2014-06-12 2014-06-13            NaN     2014-06-12  ...        None   \n",
      "72589 2014-06-12 2014-06-13            NaN     2014-06-12  ...        None   \n",
      "72590 2014-06-12 2014-06-13            NaN     2014-06-12  ...        None   \n",
      "\n",
      "      Class  Style  ProductSubcategoryID ProductModelID  SellStartDate  \\\n",
      "0        L      U                   14.0            9.0     2011-05-31   \n",
      "1        L      U                   14.0            9.0     2011-05-31   \n",
      "2        L      U                   14.0            9.0     2011-05-31   \n",
      "3        L      U                   14.0            9.0     2011-05-31   \n",
      "4        L      U                   14.0            9.0     2011-05-31   \n",
      "...     ...    ...                   ...            ...            ...   \n",
      "72586    H    None                  10.0          106.0     2012-05-30   \n",
      "72587  None   None                   NaN            NaN     2008-04-30   \n",
      "72588  None   None                   NaN            NaN     2008-04-30   \n",
      "72589  None   None                   NaN            NaN     2008-04-30   \n",
      "72590  None   None                   NaN            NaN     2008-04-30   \n",
      "\n",
      "       SellEndDate  DiscontinuedDate                               rowguid  \\\n",
      "0              NaT              None  2140F256-F705-4D67-975D-32DE03265838   \n",
      "1       2013-05-29              None  137D319D-44AD-42B2-AB61-60B9CE52B5F2   \n",
      "2       2013-05-29              None  35213547-275F-4767-805D-C8A4B8E13745   \n",
      "3       2013-05-29              None  1784BB14-D1F5-4B24-92DA-9127AD179302   \n",
      "4       2013-05-29              None  7E73AA1F-8569-4D87-9F80-AC2E513E0803   \n",
      "...            ...               ...                                   ...   \n",
      "72586   2013-05-29              None  553229B3-1AD9-4A71-A21C-2AF4332CFCE9   \n",
      "72587          NaT              None  E73E9750-603B-4131-89F5-3DD15ED5FF80   \n",
      "72588          NaT              None  C91D602E-DA52-43D2-BD7E-EB110A9392B9   \n",
      "72589          NaT              None  1CBFA85B-5C9B-4B58-9C17-95238215D926   \n",
      "72590          NaT              None  F3B140A1-B139-4BB5-B144-1B7CBBEE6C9A   \n",
      "\n",
      "               ModifiedDate_y  \n",
      "0     2014-02-08 10:01:36.827  \n",
      "1     2014-02-08 10:01:36.827  \n",
      "2     2014-02-08 10:01:36.827  \n",
      "3     2014-02-08 10:01:36.827  \n",
      "4     2014-02-08 10:01:36.827  \n",
      "...                       ...  \n",
      "72586 2014-02-08 10:01:36.827  \n",
      "72587 2014-02-08 10:01:36.827  \n",
      "72588 2014-02-08 10:01:36.827  \n",
      "72589 2014-02-08 10:01:36.827  \n",
      "72590 2014-02-08 10:01:36.827  \n",
      "\n",
      "[72591 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(workorder_df, product_df, on='ProductID', how='inner')\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Create an intermediate DataFrame to calculate total production quantity per product in the last 12 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [WorkOrderID, ProductID, OrderQty, StockedQty, ScrappedQty, StartDate, EndDate, DueDate, ScrapReasonID, ModifiedDate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "workorder_df['StartDate'] = pd.to_datetime(workorder_df['StartDate'])\n",
    "current_date = datetime.now()\n",
    "one_year_ago = current_date - timedelta(days=365)\n",
    "recent_workorders_df = workorder_df[(workorder_df['StartDate'] >= one_year_ago) & (workorder_df['StartDate'] <= current_date)]\n",
    "print(recent_workorders_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ProductID, TotalProductionQuantity]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "total_production_quantity_last_12_months = recent_workorders_df.groupby('ProductID')['OrderQty'].sum().reset_index()\n",
    "total_production_quantity_last_12_months.columns = ['ProductID', 'TotalProductionQuantity']\n",
    "print(total_production_quantity_last_12_months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Filter products with total production quantity exceeding 1,000 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ProductID, TotalProductionQuantity]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "high_production_products_df = total_production_quantity_last_12_months[total_production_quantity_last_12_months['TotalProductionQuantity'] > 1000]\n",
    "print(high_production_products_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Identify bottlenecks in the production process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       WorkOrderID  ProductID  OrderQty  StockedQty  ScrappedQty  StartDate  \\\n",
      "12              13        747         4           4            0 2011-06-03   \n",
      "13              14        748         2           2            0 2011-06-03   \n",
      "14              15        749         4           4            0 2011-06-03   \n",
      "15              16        753        14          14            0 2011-06-03   \n",
      "16              17        754        27          27            0 2011-06-03   \n",
      "...            ...        ...       ...         ...          ...        ...   \n",
      "72479        72480        995        17          17            0 2014-06-01   \n",
      "72480        72481        996         5           5            0 2014-06-01   \n",
      "72495        72496        802        12          12            0 2014-06-01   \n",
      "72496        72497        803        11          11            0 2014-06-01   \n",
      "72497        72498        804        17          17            0 2014-06-01   \n",
      "\n",
      "         EndDate    DueDate  ScrapReasonID ModifiedDate  \n",
      "12    2011-06-19 2011-06-14            NaN   2011-06-19  \n",
      "13    2011-06-19 2011-06-14            NaN   2011-06-19  \n",
      "14    2011-06-19 2011-06-14            NaN   2011-06-19  \n",
      "15    2011-06-19 2011-06-14            NaN   2011-06-19  \n",
      "16    2011-06-19 2011-06-14            NaN   2011-06-19  \n",
      "...          ...        ...            ...          ...  \n",
      "72479 2014-06-15 2014-06-12            NaN   2014-06-15  \n",
      "72480 2014-06-15 2014-06-12            NaN   2014-06-15  \n",
      "72495 2014-06-15 2014-06-12            NaN   2014-06-15  \n",
      "72496 2014-06-15 2014-06-12            NaN   2014-06-15  \n",
      "72497 2014-06-15 2014-06-12            NaN   2014-06-15  \n",
      "\n",
      "[22790 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "workorder_df['DueDate'] = pd.to_datetime(workorder_df['DueDate'])\n",
    "delayed_workorders_df = workorder_df[(workorder_df['EndDate'] > workorder_df['DueDate']) | (workorder_df['EndDate'].isna())]\n",
    "print(delayed_workorders_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Calculate the average lead time for each product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathir\\AppData\\Local\\Temp\\ipykernel_4028\\2577954330.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  workorder_df['LeadTime'].fillna((workorder_df['DueDate'] - workorder_df['StartDate']).dt.days, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ProductID  AverageLeadTime\n",
      "0            3        10.000000\n",
      "1          316        10.000000\n",
      "2          324        10.000000\n",
      "3          327        10.000000\n",
      "4          328        10.000000\n",
      "..         ...              ...\n",
      "233        995        15.550704\n",
      "234        996        15.491697\n",
      "235        997        15.021186\n",
      "236        998        15.334746\n",
      "237        999        15.360515\n",
      "\n",
      "[238 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "workorder_df['StartDate'] = pd.to_datetime(workorder_df['StartDate'])\n",
    "workorder_df['EndDate'] = pd.to_datetime(workorder_df['EndDate'])\n",
    "workorder_df['LeadTime'] = (workorder_df['EndDate'] - workorder_df['StartDate']).dt.days\n",
    "workorder_df['LeadTime'].fillna((workorder_df['DueDate'] - workorder_df['StartDate']).dt.days, inplace=True)\n",
    "average_lead_time_by_product = workorder_df.groupby('ProductID')['LeadTime'].mean().reset_index()\n",
    "average_lead_time_by_product.columns = ['ProductID', 'AverageLeadTime']\n",
    "print(average_lead_time_by_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Determine the products with the highest production costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ProductID  TotalProductionCost\n",
      "116        804        338807.743372\n",
      "1          316        331767.269503\n",
      "7          331        331588.576697\n",
      "8          350        331046.046288\n",
      "9          398        331041.854201\n",
      "..         ...                  ...\n",
      "46         734          3413.490573\n",
      "70         758          3380.478633\n",
      "68         756          3364.346593\n",
      "43         731          3347.460460\n",
      "69         757          2097.862501\n",
      "\n",
      "[238 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "workorder_df['ProductionCost'] = np.random.uniform(100, 500, size=len(workorder_df))\n",
    "total_production_cost_by_product = workorder_df.groupby('ProductID')['ProductionCost'].sum().reset_index()\n",
    "total_production_cost_by_product.columns = ['ProductID', 'TotalProductionCost']\n",
    "sorted_cost_by_product = total_production_cost_by_product.sort_values(by='TotalProductionCost', ascending=False)\n",
    "print(sorted_cost_by_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) Filter products that require special equipment for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ProductID  Count\n",
      "0            3    537\n",
      "1          316    565\n",
      "2          324    521\n",
      "3          327    535\n",
      "4          328    486\n",
      "..         ...    ...\n",
      "233        995    342\n",
      "234        996    530\n",
      "235        997    106\n",
      "236        998    119\n",
      "237        999    113\n",
      "\n",
      "[238 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "workorder_df['SpecialEquipmentRequired'] = np.random.choice([True, False], size=len(workorder_df))\n",
    "special_equipment_products_df = workorder_df[workorder_df['SpecialEquipmentRequired'] == True]\n",
    "special_equipment_products_summary = special_equipment_products_df.groupby('ProductID').size().reset_index(name='Count')\n",
    "print(special_equipment_products_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) Rank products by total production quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ProductID  TotalProductionQuantity  Rank\n",
      "0      P004                     7911     1\n",
      "1      P002                     5473     2\n",
      "2      P003                     5443     3\n",
      "3      P001                     5083     4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "workorder_df = pd.DataFrame({\n",
    "    'ProductID': np.random.choice(['P001', 'P002', 'P003', 'P004'], size=100),\n",
    "    'OrderQty': np.random.randint(1, 500, size=100)\n",
    "})\n",
    "total_production_quantity_by_product = workorder_df.groupby('ProductID')['OrderQty'].sum().reset_index()\n",
    "total_production_quantity_by_product.columns = ['ProductID', 'TotalProductionQuantity']\n",
    "ranked_products = total_production_quantity_by_product.sort_values(by='TotalProductionQuantity', ascending=False).reset_index(drop=True)\n",
    "ranked_products['Rank'] = ranked_products.index + 1\n",
    "print(ranked_products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) Find the top 5 products by total production quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ProductID  TotalProductionQuantity\n",
      "3      P004                     7911\n",
      "1      P002                     5473\n",
      "2      P003                     5443\n",
      "0      P001                     5083\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "workorder_df = pd.DataFrame({\n",
    "    'ProductID': np.random.choice(['P001', 'P002', 'P003', 'P004'], size=100),\n",
    "    'OrderQty': np.random.randint(1, 500, size=100)\n",
    "})\n",
    "total_production_quantity_by_product = workorder_df.groupby('ProductID')['OrderQty'].sum().reset_index()\n",
    "total_production_quantity_by_product.columns = ['ProductID', 'TotalProductionQuantity']\n",
    "sorted_products = total_production_quantity_by_product.sort_values(by='TotalProductionQuantity', ascending=False)\n",
    "top_5_products = sorted_products.head(5)\n",
    "print(top_5_products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19) Define a function to retrieve production details based on ProductID and OrderDate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ProductID, OrderQty, OrderDate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "workorder_df = pd.DataFrame({\n",
    "    'ProductID': np.random.choice(['P001', 'P002', 'P003', 'P004'], size=100),\n",
    "    'OrderQty': np.random.randint(1, 500, size=100),\n",
    "    'OrderDate': pd.date_range(start='2024-01-01', periods=100, freq='D')\n",
    "})\n",
    "def get_production_details(product_id, order_date, df):\n",
    "    \n",
    "    if isinstance(order_date, str):\n",
    "        order_date = pd.to_datetime(order_date)\n",
    "    \n",
    "    filtered_df = df[(df['ProductID'] == product_id) & (df['OrderDate'] == order_date)]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "product_id_to_search = 'P001'\n",
    "order_date_to_search = '2024-01-10'\n",
    "production_details = get_production_details(product_id_to_search, order_date_to_search, workorder_df)\n",
    "print(production_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20) Calculate the lead time between production orders for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductID  OrderQty  StartDate  LeadTime\n",
      "0       P001       122 2023-01-01       NaN\n",
      "3       P001       204 2023-01-04       3.0\n",
      "12      P001       181 2023-01-13       9.0\n",
      "15      P001       144 2023-01-16       3.0\n",
      "16      P001       149 2023-01-17       1.0\n",
      "..       ...       ...        ...       ...\n",
      "88      P004       295 2023-03-30       3.0\n",
      "90      P004       175 2023-04-01       2.0\n",
      "91      P004        43 2023-04-02       1.0\n",
      "94      P004       445 2023-04-05       3.0\n",
      "97      P004       287 2023-04-08       3.0\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "workorder_df = pd.DataFrame({\n",
    "    'ProductID': np.random.choice(['P001', 'P002', 'P003', 'P004'], size=100),\n",
    "    'OrderQty': np.random.randint(1, 500, size=100),\n",
    "    'StartDate': pd.date_range(start='2023-01-01', periods=100, freq='D')\n",
    "})\n",
    "workorder_df['StartDate'] = pd.to_datetime(workorder_df['StartDate'])\n",
    "def calculate_lead_time_between_orders(df):\n",
    "    df_sorted = df.sort_values(by=['ProductID', 'StartDate'])\n",
    "    df_sorted['LeadTime'] = df_sorted.groupby('ProductID')['StartDate'].diff().dt.days\n",
    "    return df_sorted\n",
    "\n",
    "lead_time_df = calculate_lead_time_between_orders(workorder_df)\n",
    "print(lead_time_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21) Analyze the efficiency of the production schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Lead Time: 3.92 days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "workorder_df = pd.DataFrame({\n",
    "    'ProductID': np.random.choice(['P001', 'P002', 'P003', 'P004'], size=100),\n",
    "    'OrderQty': np.random.randint(1, 500, size=100),\n",
    "    'StartDate': pd.date_range(start='2023-01-01', periods=100, freq='D')\n",
    "})\n",
    "workorder_df['StartDate'] = pd.to_datetime(workorder_df['StartDate'])\n",
    "def calculate_lead_time_between_orders(df):\n",
    "    df_sorted = df.sort_values(by=['ProductID', 'StartDate'])\n",
    "    df_sorted['LeadTime'] = df_sorted.groupby('ProductID')['StartDate'].diff().dt.days\n",
    "    return df_sorted\n",
    "lead_time_df = calculate_lead_time_between_orders(workorder_df)\n",
    "average_lead_time = lead_time_df['LeadTime'].mean()\n",
    "print(f\"Average Lead Time: {average_lead_time:.2f} days\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Analyzing the total production quantity over specific periods (e.g., weekly, monthly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Production Throughput:\n",
      "     Month  OrderQty\n",
      "0  2023-01      7880\n",
      "1  2023-02      7666\n",
      "2  2023-03      5883\n",
      "3  2023-04      2481\n"
     ]
    }
   ],
   "source": [
    "workorder_df['Month'] = workorder_df['StartDate'].dt.to_period('M')\n",
    "monthly_throughput = workorder_df.groupby('Month')['OrderQty'].sum().reset_index()\n",
    "print(\"Monthly Production Throughput:\")\n",
    "print(monthly_throughput)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Comparing the actual production quantities with planned or scheduled quantities to determine the fulfillment rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Fulfillment Rate:\n",
      "  ProductID  PlannedQty  ActualQty  FulfillmentRate\n",
      "0      P001        1000       5083       508.300000\n",
      "1      P002         800       5473       684.125000\n",
      "2      P003        1200       5443       453.583333\n",
      "3      P004         900       7911       879.000000\n"
     ]
    }
   ],
   "source": [
    "planned_quantities = pd.DataFrame({\n",
    "    'ProductID': ['P001', 'P002', 'P003', 'P004'],\n",
    "    'PlannedQty': [1000, 800, 1200, 900]\n",
    "})\n",
    "actual_quantities = workorder_df.groupby('ProductID')['OrderQty'].sum().reset_index()\n",
    "actual_quantities.columns = ['ProductID', 'ActualQty']\n",
    "fulfillment_df = pd.merge(planned_quantities, actual_quantities, on='ProductID')\n",
    "fulfillment_df['FulfillmentRate'] = (fulfillment_df['ActualQty'] / fulfillment_df['PlannedQty']) * 100\n",
    "\n",
    "print(\"Order Fulfillment Rate:\")\n",
    "print(fulfillment_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22) Identify products with frequent quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with Frequent Quality Issues:\n",
      "  ProductID  TotalQualityIssues\n",
      "3      P004                  16\n",
      "0      P001                  11\n",
      "1      P002                   9\n",
      "2      P003                   9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "quality_issues_df = pd.DataFrame({\n",
    "    'ProductID': np.random.choice(['P001', 'P002', 'P003', 'P004'], size=100),\n",
    "    'QualityIssue': np.random.choice([0, 1], size=100)\n",
    "})\n",
    "quality_issues_summary = quality_issues_df.groupby('ProductID')['QualityIssue'].sum().reset_index()\n",
    "quality_issues_summary.columns = ['ProductID', 'TotalQualityIssues']\n",
    "frequent_issues_products = quality_issues_summary.sort_values(by='TotalQualityIssues', ascending=False)\n",
    "print(\"Products with Frequent Quality Issues:\")\n",
    "print(frequent_issues_products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23) Assess the impact of machine downtime on production schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Downtime Duration per Machine: 24.00 hours\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "production_df = pd.DataFrame({\n",
    "    'ProductID': np.random.choice(['P001', 'P002', 'P003', 'P004'], size=100),\n",
    "    'StartDate': pd.date_range(start='2023-01-01', periods=100, freq='D'),\n",
    "    'EndDate': pd.date_range(start='2023-01-02', periods=100, freq='D'),\n",
    "    'OrderQty': np.random.randint(50, 500, size=100)\n",
    "})\n",
    "downtime_df = pd.DataFrame({\n",
    "    'MachineID': np.random.choice(['M001', 'M002'], size=10),\n",
    "    'DowntimeStart': pd.date_range(start='2023-01-01', periods=10, freq='2D'),\n",
    "    'DowntimeEnd': pd.date_range(start='2023-01-02', periods=10, freq='2D')\n",
    "})\n",
    "downtime_df['DowntimeDuration'] = (downtime_df['DowntimeEnd'] - downtime_df['DowntimeStart']).dt.total_seconds() / 3600  # in hours\n",
    "average_downtime_per_product = downtime_df['DowntimeDuration'].mean()\n",
    "print(f\"Average Downtime Duration per Machine: {average_downtime_per_product:.2f} hours\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " analysis of how downtime affects the production schedules by comparing production times before and after downtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impact of Downtime on Production Schedules:\n",
      "   ProductID  StartDate    EndDate  OrderQty  ProductionTime  \\\n",
      "0       P001 2023-01-01 2023-01-02       171            24.0   \n",
      "1       P004 2023-01-02 2023-01-03       476            24.0   \n",
      "2       P002 2023-01-03 2023-01-04       134            24.0   \n",
      "3       P001 2023-01-04 2023-01-05       253            24.0   \n",
      "4       P004 2023-01-05 2023-01-06       374            24.0   \n",
      "..       ...        ...        ...       ...             ...   \n",
      "95      P001 2023-04-06 2023-04-07       144            24.0   \n",
      "96      P003 2023-04-07 2023-04-08       276            24.0   \n",
      "97      P004 2023-04-08 2023-04-09       413            24.0   \n",
      "98      P002 2023-04-09 2023-04-10       319            24.0   \n",
      "99      P001 2023-04-10 2023-04-11       418            24.0   \n",
      "\n",
      "    AdjustedProductionTime  Impact  \n",
      "0                     48.0    24.0  \n",
      "1                     48.0    24.0  \n",
      "2                     48.0    24.0  \n",
      "3                     48.0    24.0  \n",
      "4                     48.0    24.0  \n",
      "..                     ...     ...  \n",
      "95                    48.0    24.0  \n",
      "96                    48.0    24.0  \n",
      "97                    48.0    24.0  \n",
      "98                    48.0    24.0  \n",
      "99                    48.0    24.0  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "production_df['ProductionTime'] = (production_df['EndDate'] - production_df['StartDate']).dt.total_seconds() / 3600  # in hours\n",
    "production_df['AdjustedProductionTime'] = production_df['ProductionTime'] + average_downtime_per_product\n",
    "impact_df = production_df[['ProductID', 'StartDate', 'EndDate', 'OrderQty', 'ProductionTime', 'AdjustedProductionTime']]\n",
    "impact_df['Impact'] = impact_df['AdjustedProductionTime'] - impact_df['ProductionTime']\n",
    "print(\"Impact of Downtime on Production Schedules:\")\n",
    "print(impact_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24) Determine optimal production batch sizes to minimize setup costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Production Batch Size (EOQ): 223.61 units\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "demand_rate = 1000\n",
    "setup_cost = 50 \n",
    "holding_cost = 2\n",
    "\n",
    "def calculate_eoq(demand_rate, setup_cost, holding_cost):\n",
    "    return np.sqrt((2 * demand_rate * setup_cost) / holding_cost)\n",
    "eoq = calculate_eoq(demand_rate, setup_cost, holding_cost)\n",
    "print(f\"Optimal Production Batch Size (EOQ): {eoq:.2f} units\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
